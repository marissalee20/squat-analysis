{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preprocess-data.py\n",
    "\n",
    "create train_dset, val_dset, and test_dset from Ogata et al. data\n",
    "\n",
    "Date        Time   Who      Updates\n",
    "----------  -----  -------  ----------------\n",
    "2020-11-11  11:36  Marissa  move preprocessing from ogata-model.ipynb and lstm-model.ipynb; save datasets\n",
    "2020-11-15  22:00  Rachel    make adjustments to allow for combining multiple classes (used for error analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "Read in data to generate Pandas dataframe. If generating for the first time, will take about five minutes. Otherwise, it should take about 10 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing ../data/Pose_Dataset/\n",
      "Done processing ../data/Pose_Dataset/good\n",
      "Done processing ../data/Pose_Dataset/good/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_toe\n",
      "Done processing ../data/Pose_Dataset/bad_toe/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_shallow\n",
      "Done processing ../data/Pose_Dataset/bad_shallow/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_innner_thigh\n",
      "Done processing ../data/Pose_Dataset/bad_innner_thigh/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_back_round\n",
      "Done processing ../data/Pose_Dataset/bad_back_round/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_back_warp\n",
      "Done processing ../data/Pose_Dataset/bad_back_warp/1115_3djoints_index\n",
      "Done processing ../data/Pose_Dataset/bad_head\n",
      "Done processing ../data/Pose_Dataset/bad_head/1115_3djoints_index\n"
     ]
    }
   ],
   "source": [
    "datapath = '../data/Pose_Dataset/'\n",
    "nFrames = 300 # number of frames per squat\n",
    "df_filename = '../data/all-data.pkl' # where to save concatenated data\n",
    "np_filename = '../data/np-data.npy'\n",
    "name_to_label = {\n",
    "    'bad_innner_thigh': 0,\n",
    "    'bad_back_round': 1,\n",
    "    'bad_back_warp': 2,\n",
    "    'bad_head': 3,\n",
    "    'bad_shallow': 4,\n",
    "    'bad_toe': 5,\n",
    "    'good': 6\n",
    "}\n",
    "\n",
    "#error analysis utility: for combining certain classes to see if this improves accuracy of model...if not combining any classes, pass empty matrix []\n",
    "#classes_to_combine = [['bad_innner_thigh', 'bad_head']] \n",
    "#classes_to_combine = [['bad_head', 'bad_toe']] \n",
    "#classes_to_combine = [['bad_back_warp', 'bad_back_round'], ['bad_head', 'bad_toe']] \n",
    "classes_to_combine = [['bad_back_warp', 'bad_back_round']]\n",
    "\n",
    "##have to comment out if through else opening and move the code below one tab to left if need to regenerate the pickled files.\n",
    "#do the opposite to use the saved data OR just delete the files and then regenerate them\n",
    "\n",
    "if os.path.exists(df_filename) and os.path.exists(np_filename):\n",
    "    # read in pkl file\n",
    "    df = pd.read_pickle(df_filename)\n",
    "    with open(np_filename, 'rb') as f:\n",
    "        X_train = np.load(f)\n",
    "        y_train = np.load(f)\n",
    "        X_val = np.load(f)\n",
    "        y_val = np.load(f)\n",
    "        X_test = np.load(f)\n",
    "        y_test = np.load(f)\n",
    "else:\n",
    "    # generate pkl file and npy file\n",
    "\n",
    "    # initialize arrays to fill in each loop iteration\n",
    "    filenames = []\n",
    "    datas = []\n",
    "    np_datas = []\n",
    "    labels = []\n",
    "    \n",
    "    import copy\n",
    "    # read in each squat file\n",
    "    for cur_dir, _, files in os.walk(datapath):\n",
    "        for file in files:\n",
    "            if not file.endswith('.json'):\n",
    "                continue\n",
    "            filename = os.path.join(cur_dir, file)\n",
    "            filenames.append(filename)\n",
    "\n",
    "            data = pd.read_json(filename).to_numpy()\n",
    "            data = data[1,0:nFrames] # get data for frames. Note some files have 301 frames, truncate all to first 300\n",
    "            datas.append(data)\n",
    "            np_data = np.array([np.array(d) for d in data])\n",
    "            if np_data.shape == (300, 171):\n",
    "                np_datas.append(np_data)\n",
    "                labels.append(name_to_label[cur_dir.split('/')[-2]]) #append label if appending data \n",
    "                #labels.append(name_to_label_comb[cur_dir.split('/')[-2]]) #replaced line above to check out the error analysis\n",
    "        print(f\"Done processing {cur_dir}\")\n",
    "        # move arrays into dataframe\n",
    "    datas = np.array(datas) # convert to array so we can loop through\n",
    "    d = {'filename': filenames}\n",
    "    for i in range(nFrames):\n",
    "        d[str(i)] = datas[:,i]\n",
    "    df = pd.DataFrame(data=d)\n",
    "\n",
    "    #add label column based on filename (also makes new naming for combined classes)\n",
    "    new_classes = ['_or_'.join(classes) for classes in classes_to_combine]\n",
    "    new_labels = []\n",
    "    for i in range(len(df)):\n",
    "        current_label = df['filename'][i].split('/')[3]\n",
    "        for j in range(len(classes_to_combine)):\n",
    "            if current_label in classes_to_combine[j]:\n",
    "                current_label = new_classes[j]\n",
    "        new_labels.append(current_label)\n",
    "    df['label'] = new_labels  \n",
    "    \n",
    "    # save to pkl\n",
    "    df.to_pickle(df_filename)\n",
    "\n",
    "    # write data into numpy arrays and save\n",
    "    np_datas = np.stack(np_datas)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    #separate data into classes \n",
    "    num_classes = len(name_to_label)\n",
    "    pre_data = []\n",
    "    pre_labels = []   \n",
    "    for i in range(num_classes):\n",
    "        indices = np.where(labels == i) #finding indices where particular class is found in labels\n",
    "        pre_labels.append(labels[indices])\n",
    "        pre_data.append(np_datas[indices])\n",
    "        \n",
    "    #choose to keep only half of the data from the 2 classes we're combining\n",
    "    modified_name_to_label = copy.deepcopy(name_to_label)\n",
    "\n",
    "    for i in range(len(classes_to_combine)):\n",
    "        for j in classes_to_combine[i]:\n",
    "            label = name_to_label[j]\n",
    "            label_to_use = name_to_label[ classes_to_combine[i][0] ] #choosing the first label in the group of classes to combine\n",
    "            modified_name_to_label[j] = label_to_use\n",
    "\n",
    "            fraction = 1/len(classes_to_combine[i]) #if don't want to reduce data such that data in the combined class is roughly equal to data in the other non-combined classes, make fraction = 1\n",
    "            pre_data[label] = pre_data[label][0:int(fraction*len( pre_data[label]))]\n",
    "            pre_labels[label] = [label_to_use]*int(fraction*len( pre_labels[label])) #replacing original label with the new one based on the combined classes\n",
    "\n",
    "    #recombine the pre-data and pre-labels\n",
    "    np_datas_combined = [] \n",
    "    labels_combined = []\n",
    "\n",
    "    for i in range(len(pre_labels)):\n",
    "        np_datas_combined.extend(pre_data[i])\n",
    "        labels_combined.extend(pre_labels[i])\n",
    "    np_datas_combined = np.array(np_datas_combined)\n",
    "    labels_combined =   np.array(labels_combined)  \n",
    "\n",
    "    #shuffle the data\n",
    "    np_datas, labels = shuffle(np_datas_combined, labels_combined) #note this is using the combined frames....not the original non-combined ones  \n",
    "\n",
    "    #modify name_to_label and labels to account for the renumbered classes\n",
    "    def reorder(name_to_label, labels ):\n",
    "        #create a set from labels to get unique set of labels\n",
    "        sorted_unique_labels = list( set(labels) )\n",
    "        sorted_unique_labels.sort() \n",
    "\n",
    "\n",
    "        for i in range(len(sorted_unique_labels)):\n",
    "            for key,value in name_to_label.items():\n",
    "                if value == sorted_unique_labels[i]:\n",
    "                    name_to_label[key] = i #adjust the value in the name to label dict\n",
    "                    labels = np.where(labels==value, i, labels) #adjust the value in labels\n",
    "        return name_to_label, labels\n",
    "    \n",
    "    name_to_label, labels =  reorder(modified_name_to_label, labels)\n",
    "    \n",
    "    \n",
    "    #original splitting of train, val, test\n",
    "    n = np_datas.shape[0]\n",
    "    split_indices = [int(n * 0.8), int(n * 0.9)]\n",
    "    train_indices, val_indices, test_indices = np.split(np.random.choice(n, n, replace=False), split_indices)\n",
    "\n",
    "    X_train = np_datas[train_indices]\n",
    "    y_train = labels[train_indices]\n",
    "\n",
    "    X_val = np_datas[val_indices]\n",
    "    y_val = labels[val_indices]\n",
    "\n",
    "    X_test = np_datas[test_indices]\n",
    "    y_test = labels[test_indices]\n",
    "\n",
    "    with open(np_filename, 'wb') as f:\n",
    "        np.save(f, X_train)\n",
    "        np.save(f, y_train)\n",
    "        np.save(f, X_val)\n",
    "        np.save(f, y_val)\n",
    "        np.save(f, X_test)\n",
    "        np.save(f, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           good\n",
      "1           good\n",
      "2           good\n",
      "3           good\n",
      "4           good\n",
      "          ...   \n",
      "1996    bad_head\n",
      "1997    bad_head\n",
      "1998    bad_head\n",
      "1999    bad_head\n",
      "2000    bad_head\n",
      "Name: label, Length: 2001, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first five rows of the dataframe. The 'filename' column contains full filepath + name of each squat, and the remaining columns contain pose data for each of 300 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/Pose_Dataset/good/1115_3djoints_index/...</td>\n",
       "      <td>[0.43120177353718403, 0.797377414334803, 0.844...</td>\n",
       "      <td>[0.430941564889928, 0.79869170732256, 0.847091...</td>\n",
       "      <td>[0.431044555308539, 0.799997781067416, 0.84760...</td>\n",
       "      <td>[0.431592316178638, 0.7988144430510611, 0.8469...</td>\n",
       "      <td>[0.4311132590348, 0.7942079960716251, 0.840107...</td>\n",
       "      <td>[0.43193753462167306, 0.7949407220012981, 0.84...</td>\n",
       "      <td>[0.432750845147567, 0.7839057041264701, 0.8325...</td>\n",
       "      <td>[0.432541413484046, 0.787418809894588, 0.83614...</td>\n",
       "      <td>[0.431894497467298, 0.786059366307652, 0.83555...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.43357581090852304, 0.7943466004531391, 0.84...</td>\n",
       "      <td>[0.433069769111656, 0.7938311318961081, 0.8431...</td>\n",
       "      <td>[0.431030331629899, 0.786474443905499, 0.83585...</td>\n",
       "      <td>[0.43115121328079503, 0.7842615868752231, 0.83...</td>\n",
       "      <td>[0.43390441871996305, 0.7924671389584511, 0.84...</td>\n",
       "      <td>[0.43198091643781905, 0.7867065528136351, 0.83...</td>\n",
       "      <td>[0.43174849778878904, 0.783046079262931, 0.836...</td>\n",
       "      <td>[0.43123957336803503, 0.787923224200576, 0.840...</td>\n",
       "      <td>[0.428997741451614, 0.780915252148985, 0.83353...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/Pose_Dataset/good/1115_3djoints_index/...</td>\n",
       "      <td>[0.47551463277682005, 0.9215836428119221, 0.93...</td>\n",
       "      <td>[0.47563254721491705, 0.9217684412264681, 0.93...</td>\n",
       "      <td>[0.47606479372639904, 0.921504059759201, 0.932...</td>\n",
       "      <td>[0.476369782218, 0.920659233360356, 0.93398515...</td>\n",
       "      <td>[0.474865629960791, 0.9185499246891451, 0.9351...</td>\n",
       "      <td>[0.47621913132710003, 0.9194576930028691, 0.93...</td>\n",
       "      <td>[0.47541189727106403, 0.916291807802979, 0.935...</td>\n",
       "      <td>[0.473958178841594, 0.9117857030781501, 0.9319...</td>\n",
       "      <td>[0.47338005686455703, 0.907825476525932, 0.933...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.43516232461652304, 0.7482315863841671, 0.81...</td>\n",
       "      <td>[0.440398428175206, 0.771004741367683, 0.83682...</td>\n",
       "      <td>[0.45157124879577604, 0.815575642811675, 0.875...</td>\n",
       "      <td>[0.456352779376737, 0.843149297107819, 0.90124...</td>\n",
       "      <td>[0.464314572629178, 0.8598558365912851, 0.9082...</td>\n",
       "      <td>[0.46697763869442105, 0.8769539497506571, 0.92...</td>\n",
       "      <td>[0.46801772225950805, 0.8857252811475381, 0.92...</td>\n",
       "      <td>[0.468906910070493, 0.89422190287234, 0.928794...</td>\n",
       "      <td>[0.47246470516002803, 0.9024032699077711, 0.93...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/Pose_Dataset/good/1115_3djoints_index/...</td>\n",
       "      <td>[0.487507568770135, 0.945001119666321, 0.95042...</td>\n",
       "      <td>[0.48724964719018404, 0.9447277868278361, 0.94...</td>\n",
       "      <td>[0.48733040533680005, 0.9444814068387251, 0.95...</td>\n",
       "      <td>[0.487969080175346, 0.946172353218329, 0.95415...</td>\n",
       "      <td>[0.48801193176894003, 0.946446475083851, 0.954...</td>\n",
       "      <td>[0.48742002510173404, 0.9443007012276421, 0.95...</td>\n",
       "      <td>[0.48699883703371705, 0.944366404361722, 0.957...</td>\n",
       "      <td>[0.48672516046768005, 0.9434340433389351, 0.95...</td>\n",
       "      <td>[0.48594678261619706, 0.9419660089707981, 0.95...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.48502701306215, 0.9386721636737401, 0.95784...</td>\n",
       "      <td>[0.48510789168053, 0.9385537482653441, 0.95760...</td>\n",
       "      <td>[0.48517004926523405, 0.9378531640723361, 0.95...</td>\n",
       "      <td>[0.485991932994121, 0.9392084318376931, 0.9576...</td>\n",
       "      <td>[0.48617870299984006, 0.9400844966051861, 0.95...</td>\n",
       "      <td>[0.48613420586339506, 0.939901991724413, 0.950...</td>\n",
       "      <td>[0.48738268976887006, 0.9421225640340241, 0.95...</td>\n",
       "      <td>[0.487048790933767, 0.941068299266387, 0.94779...</td>\n",
       "      <td>[0.48686638446639, 0.9400423518104981, 0.94476...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/Pose_Dataset/good/1115_3djoints_index/...</td>\n",
       "      <td>[0.47153572199932403, 0.857707360049973, 0.912...</td>\n",
       "      <td>[0.47160060745792703, 0.8573000747132821, 0.91...</td>\n",
       "      <td>[0.47036495298267605, 0.8531030652053331, 0.90...</td>\n",
       "      <td>[0.47240727772132, 0.860811007425445, 0.915781...</td>\n",
       "      <td>[0.46991840338782903, 0.8573401020290371, 0.91...</td>\n",
       "      <td>[0.47183890308743204, 0.8578533481614711, 0.91...</td>\n",
       "      <td>[0.469546441113654, 0.85047357179348, 0.904737...</td>\n",
       "      <td>[0.472174902614971, 0.854945950506319, 0.91187...</td>\n",
       "      <td>[0.46757983379684404, 0.8449749239116151, 0.90...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.39646774404282203, 0.6211367265235841, 0.68...</td>\n",
       "      <td>[0.401195957721987, 0.6348000804749631, 0.7068...</td>\n",
       "      <td>[0.40244821179802404, 0.6407111917934291, 0.71...</td>\n",
       "      <td>[0.40574182411201004, 0.6531848616857611, 0.72...</td>\n",
       "      <td>[0.40859117574242604, 0.6741368173148691, 0.74...</td>\n",
       "      <td>[0.409277574312078, 0.6778921720769541, 0.7455...</td>\n",
       "      <td>[0.409182634792002, 0.682084981652292, 0.75031...</td>\n",
       "      <td>[0.412567976505038, 0.69516563040747, 0.759781...</td>\n",
       "      <td>[0.416437388706261, 0.701491497695204, 0.77149...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/Pose_Dataset/good/1115_3djoints_index/...</td>\n",
       "      <td>[0.429601500322751, 0.783594002919882, 0.85645...</td>\n",
       "      <td>[0.429098468390165, 0.782670444059926, 0.85530...</td>\n",
       "      <td>[0.427422668309312, 0.7961000337023271, 0.8651...</td>\n",
       "      <td>[0.42637371482796504, 0.792436500581507, 0.860...</td>\n",
       "      <td>[0.428166812790336, 0.7952940669376181, 0.8572...</td>\n",
       "      <td>[0.431101179028114, 0.802679301508866, 0.86046...</td>\n",
       "      <td>[0.432936960033085, 0.8145019413273441, 0.8702...</td>\n",
       "      <td>[0.42974683950958104, 0.798189564712512, 0.849...</td>\n",
       "      <td>[0.42703067511998005, 0.78949910636523, 0.8287...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.41955155105455605, 0.763059769062838, 0.812...</td>\n",
       "      <td>[0.42026874329713204, 0.764480316734774, 0.814...</td>\n",
       "      <td>[0.423640851070867, 0.767806562354688, 0.82477...</td>\n",
       "      <td>[0.424138022771448, 0.77757690823553, 0.833903...</td>\n",
       "      <td>[0.42191628340839504, 0.7743406955236951, 0.82...</td>\n",
       "      <td>[0.41709202516695304, 0.779285451111398, 0.833...</td>\n",
       "      <td>[0.416834936163375, 0.786854140876982, 0.83885...</td>\n",
       "      <td>[0.417435167731089, 0.7868228604867471, 0.8449...</td>\n",
       "      <td>[0.41993718389974805, 0.7979789921096461, 0.85...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  ../data/Pose_Dataset/good/1115_3djoints_index/...   \n",
       "1  ../data/Pose_Dataset/good/1115_3djoints_index/...   \n",
       "2  ../data/Pose_Dataset/good/1115_3djoints_index/...   \n",
       "3  ../data/Pose_Dataset/good/1115_3djoints_index/...   \n",
       "4  ../data/Pose_Dataset/good/1115_3djoints_index/...   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [0.43120177353718403, 0.797377414334803, 0.844...   \n",
       "1  [0.47551463277682005, 0.9215836428119221, 0.93...   \n",
       "2  [0.487507568770135, 0.945001119666321, 0.95042...   \n",
       "3  [0.47153572199932403, 0.857707360049973, 0.912...   \n",
       "4  [0.429601500322751, 0.783594002919882, 0.85645...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [0.430941564889928, 0.79869170732256, 0.847091...   \n",
       "1  [0.47563254721491705, 0.9217684412264681, 0.93...   \n",
       "2  [0.48724964719018404, 0.9447277868278361, 0.94...   \n",
       "3  [0.47160060745792703, 0.8573000747132821, 0.91...   \n",
       "4  [0.429098468390165, 0.782670444059926, 0.85530...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [0.431044555308539, 0.799997781067416, 0.84760...   \n",
       "1  [0.47606479372639904, 0.921504059759201, 0.932...   \n",
       "2  [0.48733040533680005, 0.9444814068387251, 0.95...   \n",
       "3  [0.47036495298267605, 0.8531030652053331, 0.90...   \n",
       "4  [0.427422668309312, 0.7961000337023271, 0.8651...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [0.431592316178638, 0.7988144430510611, 0.8469...   \n",
       "1  [0.476369782218, 0.920659233360356, 0.93398515...   \n",
       "2  [0.487969080175346, 0.946172353218329, 0.95415...   \n",
       "3  [0.47240727772132, 0.860811007425445, 0.915781...   \n",
       "4  [0.42637371482796504, 0.792436500581507, 0.860...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  [0.4311132590348, 0.7942079960716251, 0.840107...   \n",
       "1  [0.474865629960791, 0.9185499246891451, 0.9351...   \n",
       "2  [0.48801193176894003, 0.946446475083851, 0.954...   \n",
       "3  [0.46991840338782903, 0.8573401020290371, 0.91...   \n",
       "4  [0.428166812790336, 0.7952940669376181, 0.8572...   \n",
       "\n",
       "                                                   5  \\\n",
       "0  [0.43193753462167306, 0.7949407220012981, 0.84...   \n",
       "1  [0.47621913132710003, 0.9194576930028691, 0.93...   \n",
       "2  [0.48742002510173404, 0.9443007012276421, 0.95...   \n",
       "3  [0.47183890308743204, 0.8578533481614711, 0.91...   \n",
       "4  [0.431101179028114, 0.802679301508866, 0.86046...   \n",
       "\n",
       "                                                   6  \\\n",
       "0  [0.432750845147567, 0.7839057041264701, 0.8325...   \n",
       "1  [0.47541189727106403, 0.916291807802979, 0.935...   \n",
       "2  [0.48699883703371705, 0.944366404361722, 0.957...   \n",
       "3  [0.469546441113654, 0.85047357179348, 0.904737...   \n",
       "4  [0.432936960033085, 0.8145019413273441, 0.8702...   \n",
       "\n",
       "                                                   7  \\\n",
       "0  [0.432541413484046, 0.787418809894588, 0.83614...   \n",
       "1  [0.473958178841594, 0.9117857030781501, 0.9319...   \n",
       "2  [0.48672516046768005, 0.9434340433389351, 0.95...   \n",
       "3  [0.472174902614971, 0.854945950506319, 0.91187...   \n",
       "4  [0.42974683950958104, 0.798189564712512, 0.849...   \n",
       "\n",
       "                                                   8  ...  \\\n",
       "0  [0.431894497467298, 0.786059366307652, 0.83555...  ...   \n",
       "1  [0.47338005686455703, 0.907825476525932, 0.933...  ...   \n",
       "2  [0.48594678261619706, 0.9419660089707981, 0.95...  ...   \n",
       "3  [0.46757983379684404, 0.8449749239116151, 0.90...  ...   \n",
       "4  [0.42703067511998005, 0.78949910636523, 0.8287...  ...   \n",
       "\n",
       "                                                 291  \\\n",
       "0  [0.43357581090852304, 0.7943466004531391, 0.84...   \n",
       "1  [0.43516232461652304, 0.7482315863841671, 0.81...   \n",
       "2  [0.48502701306215, 0.9386721636737401, 0.95784...   \n",
       "3  [0.39646774404282203, 0.6211367265235841, 0.68...   \n",
       "4  [0.41955155105455605, 0.763059769062838, 0.812...   \n",
       "\n",
       "                                                 292  \\\n",
       "0  [0.433069769111656, 0.7938311318961081, 0.8431...   \n",
       "1  [0.440398428175206, 0.771004741367683, 0.83682...   \n",
       "2  [0.48510789168053, 0.9385537482653441, 0.95760...   \n",
       "3  [0.401195957721987, 0.6348000804749631, 0.7068...   \n",
       "4  [0.42026874329713204, 0.764480316734774, 0.814...   \n",
       "\n",
       "                                                 293  \\\n",
       "0  [0.431030331629899, 0.786474443905499, 0.83585...   \n",
       "1  [0.45157124879577604, 0.815575642811675, 0.875...   \n",
       "2  [0.48517004926523405, 0.9378531640723361, 0.95...   \n",
       "3  [0.40244821179802404, 0.6407111917934291, 0.71...   \n",
       "4  [0.423640851070867, 0.767806562354688, 0.82477...   \n",
       "\n",
       "                                                 294  \\\n",
       "0  [0.43115121328079503, 0.7842615868752231, 0.83...   \n",
       "1  [0.456352779376737, 0.843149297107819, 0.90124...   \n",
       "2  [0.485991932994121, 0.9392084318376931, 0.9576...   \n",
       "3  [0.40574182411201004, 0.6531848616857611, 0.72...   \n",
       "4  [0.424138022771448, 0.77757690823553, 0.833903...   \n",
       "\n",
       "                                                 295  \\\n",
       "0  [0.43390441871996305, 0.7924671389584511, 0.84...   \n",
       "1  [0.464314572629178, 0.8598558365912851, 0.9082...   \n",
       "2  [0.48617870299984006, 0.9400844966051861, 0.95...   \n",
       "3  [0.40859117574242604, 0.6741368173148691, 0.74...   \n",
       "4  [0.42191628340839504, 0.7743406955236951, 0.82...   \n",
       "\n",
       "                                                 296  \\\n",
       "0  [0.43198091643781905, 0.7867065528136351, 0.83...   \n",
       "1  [0.46697763869442105, 0.8769539497506571, 0.92...   \n",
       "2  [0.48613420586339506, 0.939901991724413, 0.950...   \n",
       "3  [0.409277574312078, 0.6778921720769541, 0.7455...   \n",
       "4  [0.41709202516695304, 0.779285451111398, 0.833...   \n",
       "\n",
       "                                                 297  \\\n",
       "0  [0.43174849778878904, 0.783046079262931, 0.836...   \n",
       "1  [0.46801772225950805, 0.8857252811475381, 0.92...   \n",
       "2  [0.48738268976887006, 0.9421225640340241, 0.95...   \n",
       "3  [0.409182634792002, 0.682084981652292, 0.75031...   \n",
       "4  [0.416834936163375, 0.786854140876982, 0.83885...   \n",
       "\n",
       "                                                 298  \\\n",
       "0  [0.43123957336803503, 0.787923224200576, 0.840...   \n",
       "1  [0.468906910070493, 0.89422190287234, 0.928794...   \n",
       "2  [0.487048790933767, 0.941068299266387, 0.94779...   \n",
       "3  [0.412567976505038, 0.69516563040747, 0.759781...   \n",
       "4  [0.417435167731089, 0.7868228604867471, 0.8449...   \n",
       "\n",
       "                                                 299 label  \n",
       "0  [0.428997741451614, 0.780915252148985, 0.83353...  good  \n",
       "1  [0.47246470516002803, 0.9024032699077711, 0.93...  good  \n",
       "2  [0.48686638446639, 0.9400423518104981, 0.94476...  good  \n",
       "3  [0.416437388706261, 0.701491497695204, 0.77149...  good  \n",
       "4  [0.41993718389974805, 0.7979789921096461, 0.85...  good  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print number of examples in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good: 293\n",
      "bad_toe: 295\n",
      "bad_shallow: 319\n",
      "bad_innner_thigh: 230\n",
      "bad_back_warp_or_bad_back_round: 592\n",
      "bad_head: 272\n",
      "nClasses: 6\n",
      "\n",
      " Train\n",
      "0: 192\n",
      "1: 232\n",
      "2: 219\n",
      "3: 252\n",
      "4: 235\n",
      "5: 233\n",
      "\n",
      " Val\n",
      "0: 20\n",
      "1: 30\n",
      "2: 25\n",
      "3: 39\n",
      "4: 29\n",
      "5: 27\n",
      "\n",
      " Test\n",
      "0: 17\n",
      "1: 34\n",
      "2: 28\n",
      "3: 28\n",
      "4: 31\n",
      "5: 33\n"
     ]
    }
   ],
   "source": [
    "df_labels = df.label.unique()\n",
    "for label in df_labels:\n",
    "    print('%s: %i' %(label,sum(df['label']==label)))\n",
    "\n",
    "nClasses = len(df_labels)\n",
    "print('nClasses:', nClasses)\n",
    "\n",
    "print('\\n Train')\n",
    "df_labels = df.label.unique()\n",
    "for i in range(nClasses):\n",
    "    print('%s: %i' %(i,sum(y_train==i)))\n",
    "\n",
    "print('\\n Val')\n",
    "df_labels = df.label.unique()\n",
    "for i in range(nClasses):\n",
    "    print('%s: %i' %(i,sum(y_val==i)))\n",
    "\n",
    "print('\\n Test')\n",
    "df_labels = df.label.unique()\n",
    "for i in range(nClasses):\n",
    "    print('%s: %i' %(i,sum(y_test==i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert y-vals to one-hot representation # REMEMBER TO ONLY RUN THIS ONCE\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train,num_classes=nClasses)\n",
    "y_val_onehot = tf.keras.utils.to_categorical(y_val,num_classes=nClasses)\n",
    "y_test_onehot = tf.keras.utils.to_categorical(y_test,num_classes=nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "train_dset = tf.data.Dataset.from_tensor_slices((X_train,y_train_onehot)).batch(BATCH_SIZE)\n",
    "val_dset = tf.data.Dataset.from_tensor_slices((X_val,y_val_onehot)).batch(BATCH_SIZE)\n",
    "test_dset = tf.data.Dataset.from_tensor_slices((X_test,y_test_onehot)).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "tf.data.experimental.save(train_dset,'../data/dsets/train_dset')\n",
    "tf.data.experimental.save(val_dset,'../data/dsets/val_dset')\n",
    "tf.data.experimental.save(test_dset,'../data/dsets/test_dset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 300, 171), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print element_spec for input to loading model in other notebooks\n",
    "train_dset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good' 'bad_toe' 'bad_shallow' 'bad_innner_thigh'\n",
      " 'bad_back_warp_or_bad_back_round' 'bad_head'] \n",
      " {'bad_innner_thigh': 0, 'bad_back_round': 1, 'bad_back_warp': 1, 'bad_head': 2, 'bad_shallow': 3, 'bad_toe': 4, 'good': 5}\n"
     ]
    }
   ],
   "source": [
    "##variables to use for the confusion matrices\n",
    "print(df_labels,'\\n', name_to_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display_labels = [] list is df_labels but ordering must be adjusted to go from smallest to largest  based on the values in name_to_label\n",
    "\n",
    "ex. for df_labels = ['good' 'bad_toe' 'bad_shallow' 'bad_innner_thigh_or_bad_head'\n",
    " 'bad_back_round' 'bad_back_warp']\n",
    " \n",
    " and name_to_label = {'bad_innner_thigh': 0, 'bad_back_round': 1, 'bad_back_warp': 2, 'bad_head': 0, 'bad_shallow': 3, 'bad_toe': 4, 'good': 5}\n",
    " \n",
    " display_labels = ['bad_innner_thigh_or_bad_head', 'bad_back_round', 'bad_back_warp', 'bad_shallow', 'bad_toe', 'good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_labels = ['bad_inner_thigh', 'bad_back_warp_or_bad_back_round', 'bad_head', 'bad_shallow', 'bad_toe', 'good']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
